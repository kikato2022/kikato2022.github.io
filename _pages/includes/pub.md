
# üìù Publications

> ( <sup>*</sup> equal contribution, <sup>#</sup> corresponding author)

## üß† Neuroscience
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Neural Computation 2022</div><img src='images/nerualcom.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Inferring mechanisms of auditory attentional modulation with deep neural networks](./files/neural.pdf)

Ting-Yu Kuo, Yuanda Liao, **Kai Li**, Bo Hong, Xiaolin Hu.

<a href="https://github.com/liaoyd16/cocktail_lk"><img src="https://img.shields.io/github/stars/liaoyd16/cocktail_lk?style=social&amp;label=Code+Stars" alt=""></a> <strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:ufrVoPGSRksC'></span></strong>

</div>
</div>

## üéº Music Separation

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2024</div><img src='images/sub-to-go.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Subnetwork-to-go: Elastic Neural Network with Dynamic Training and Customizable Inference](https://arxiv.org/pdf/2312.03464)

**Kai Li**, Yi Luo.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:aqlVkmm33-oC'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SDX Workshop 2023</div><img src='images/sdx.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[One-page Report for Tencent AI Lab‚Äôs CDX 2023 System](https://sdx-workshop.github.io/papers/Li.pdf)

**Kai Li**, Yi Luo.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:M3ejUd6NZC8C'></span></strong>

</div>
</div>

## üéô Speech Separation

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Interspeech 2023</div><img src='images/avlit.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Audio-Visual Speech Separation in Noisy Environments with a Lightweight Iterative Model](https://arxiv.org/pdf/2306.00160)

H√©ctor Martel, Julius Richter, **Kai Li**, Xiaolin Hu and Timo Gerkmann.

<a href="https://github.com/hmartelb/avlit"><img src="https://img.shields.io/github/stars/hmartelb/avlit?style=social&amp;label=Code+Stars" alt=""></a> \| <strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:hqOjcs7Dif8C'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Interspeech 2023</div><img src='images/s4m.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Neural State-Space Model Approach to Efficient Speech Separation](https://arxiv.org/pdf/2305.16932)

Chenchen, Chao-Han Huck Yang, **Kai Li**, Yuchen Hu, Pin-Jui Ku and Eng Siong Chng.

<a href="https://github.com/JusperLee/S4M"><img src="https://img.shields.io/github/stars/JusperLee/S4M?style=social&amp;label=Code+Stars" alt=""></a> \| <strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:UebtZRa9Y70C'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2022</div><img src='images/ctcnet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An Audio-Visual Speech Separation Model Inspired by Cortico-Thalamo-Cortical Circuits](https://arxiv.org/abs/2212.10744)

**Kai Li**, Fenghua Xie, Hang Chen, Kexin Yuan, Xiaolin Hu.

[**Demo Page**](./project/CTCNet) \|<a href="https://github.com/JusperLee/CTCNet"><img src="https://img.shields.io/github/stars/JusperLee/CTCNet?style=social&amp;label=Code+Stars" alt=""></a> <strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:roLk4NBRz8UC'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2023</div><img src='images/tdanet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An efficient encoder-decoder architecture with top-down attention for speech separation](https://arxiv.org/pdf/2209.15200)

**Kai Li**, Runxuan Yang, Xiaolin Hu.

[![Áü•‰πé](https://img.shields.io/badge/Áü•‰πé-TDANet(ICLR 2023)-0084FF.svg)](https://zhuanlan.zhihu.com/p/605100121) \| 
[**Audio Demo Page**](./project/TDANet) \| <a href="https://github.com/JusperLee/TDANet"><img src="https://img.shields.io/github/stars/JusperLee/TDANet?style=social&amp;label=Code+Stars" alt=""></a> <strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:LkGwnXOMwfcC'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">InterSpeech 2022</div><img src='images/overss.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
  
[On the Use of Deep Mask Estimation Module for Neural Source Separation Systems](http://arxiv.org/pdf/2206.07347v1)

**Kai Li**, Xiaolin Hu, Yi Luo.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:_FxGoFyzp5QC'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2023</div><img src='images/causal.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[On the Design and Training Strategies for RNN-based Online Neural Speech Separation Systems](http://arxiv.org/pdf/2206.07347v1)

**Kai Li**, Yi Luo.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:YsMSGLbcyi4C'></span></strong>
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2021</div><img src='images/afrcnn.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Speech Separation Using an Asynchronous Fully Recurrent Convolutional Neural Network](https://papers.nips.cc/paper/2021/file/be1bc7997695495f756312886f566110-Paper.pdf)

Xiaolin Hu<sup>*, #</sup>, **Kai Li$^*$**, Weiyi Zhang, Yi Luo, Jean-Marie Lemercier, Timo Gerkmann.

[![Áü•‰πé](https://img.shields.io/badge/Áü•‰πé-AFRCNN(NeuralPS 2021)-0084FF.svg)](https://zhuanlan.zhihu.com/p/508868699) \| [**Audio Demo Page**](./project/AFRCNN) \| [**Speech Enhancement Demo**](./project/AFRCNN-Enh) \| <a href="https://github.com/JusperLee/AFRCNN-For-Speech-Separation"><img src="https://img.shields.io/github/stars/JusperLee/AFRCNN-For-Speech-Separation?style=social&amp;label=Code+Stars" alt=""></a> <strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:zYLM7Y9cAGgC'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Bachelor Degree Thesis</div><img src='images/Bachelor-Degree-Thesis.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Research on Speech Separation Based on Audio Visual Model]()

**Kai Li**, Xiaolin Hu<sup>#</sup>, Jianqiang Huang<sup>#</sup>.

[**Audio Project Page**](./project/Pure-Audio/index.html) \| [**Audio-visual Project Page**](./project/AV-Demo/AV-Model-Demo.html)

</div>
</div>

## üñºÔ∏è Computer Vision

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2024</div><img src='images/leformer.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LEFormer: A Hybrid CNN-Transformer Architecture for Accurate Lake Extraction from Remote Sensing Imagery](https://arxiv.org/pdf/2308.04397)

Ben Chen, Xuechao Zou, Yu Zhang, Jiayu Li, **Kai Li**, Pin Tao.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:8k81kl-MbHgC'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECAI 2023</div><img src='images/pmaa.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PMAA: A Progressive Multi-scale Attention Autoencoder Model for High-Performance Cloud Removal from Multi-temporal Satellite Imagery](https://arxiv.org/pdf/2303.16565.pdf)

Xuechao Zou<sup>*</sup>, **Kai Li<sup>*</sup>**, Junliang Xing, Pin Tao<sup>#</sup>, Yachao Cui.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:Se3iqnhoufwC'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Submitted IEEE Transactions on Industrial Informatics</div><img src='images/CL-gan.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Single Image Super-Resolution through Image Pixel Information Clustering and Generative Adversarial Network]()

**Kai Li**, Jianqiang Huang<sup>#</sup>, Jinfang Jia, Yu Zhu, Li Wu, Xiaoying Wang.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IET Image Processing 2020</div><img src='images/resolution_servey.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Survey of Single Image Super Resolution Reconstruction](./files/A_Survey_of_Single_Image_Super_Resolution_Reconstr.pdf)

**Kai Li**, Shenghao Yang, Runting Dong, Jianqiang Huang<sup>#</sup>, Xiaoying Wang.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:u5HHmVD_uO8C'></span></strong>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISPA 2019</div><img src='images/lapras-GAN.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Single Image Super-resolution Reconstruction of Enhanced Loss Function with Multi-GPU Training](./files/Single_Image_Super-Resolution_Reconstruction_of_Enhanced_Loss_Function_with_Multi-GPU_Training.pdf)

Jianqiang Huang<sup>*, #</sup>, **Kai Li$^*$**, Xiaoying Wang.

<strong><span class='show_paper_citations' data='fHkHcMsAAAAJ:9yKSN-GCB0IC'></span></strong>

</div>
</div>
